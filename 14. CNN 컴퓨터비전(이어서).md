## 14. CNN 컴퓨터비전(이어서)

### CNN 구조(이어서)

- ResNet(잔차 네트워크)
  - 2015년 ILSVRC 우승모델
  - ResNet-152 : 152개의 합성곱 층 사용, 파라미터 수는 작음
  - 잔차유닛(residual unit, RU)
    - 많은 층으로 인한 많은 계산을 줄이기 위해 잔차 유닛을 활용함.
    - 목적함수 h(x) 대신 스킵연결을 추가하여 f(x)=h(x)-x를 학습함
      - <img src="https://postfiles.pstatic.net/MjAxOTEwMTFfMzkg/MDAxNTcwODAyMDk5MjQz.h-EDH_Z4HsXmBggcNNwj2fb8o1Vmm4GQ5l9UsCxDZDQg.Xyi9ZkPV0BKtELxrwR2LmE7vxzEZF4uSOiTFA4naWxEg.PNG.yunakim0808/image.png?type=w773" alt="img" style="zoom:50%;" />
      - 
    - 스킵 연결을 많이 추가하여 일부 층이 아직 학습되지 않았어도 영향을 받지않고 훈련을 시작할 수 있음.
      - <img src="http://formal.hknu.ac.kr/handson-ml2/slides/images/ch14/homl14-21.png" alt="img" style="zoom:50%;" />
    - 구조가 단순하고 GoogLeNet과 똑같이 시작하고 종료하지만, 중간에 잔차유닛을 매우 깊게 쌓음.
      - ![img](https://blog.kakaocdn.net/dn/bMhdo2/btqYwhpnLML/nWTDCkjdbXqaHpcWN3TU51/img.png)
    - 특성맵의 수가 몇개의 잔차유닛마다 두배로 늘어나지만, 스트라이드가 2인 합성곱층을 사용하여 높이와 너비가 절반이 됨.
      - 스킵 연결시 입 출력 크기 차이가 생겨 바로 연결되지 않으므로 스킵 연결을 스트라이드가 2인 합성곱에 통과시킨다.
- Xception(eXtreme inception)
  - GoogLeNet의 변종(ResNet을 합성함)
  - 케라스의 창시자인 프랑수아 숄레가 제안
  - 인셉션 모듈 대신 깊이별 분리합성곱 층을 사용함
  - 분리합성곱 층
    - 공간별 패턴인식 합성곱층과 깊이별 패턴인신 합성곱 층을 분리하여 연속적으로 적용
    - 공간별 패턴인식 : 형태인식
    - 깊이별 패턴인식 : 채널사이의 패턴 인식
    - <img src="http://formal.hknu.ac.kr/handson-ml2/slides/images/ch14/homl14-24b.png" alt="img" style="zoom:50%;" />
    - 입력층에 채널이 많을 때 활용
    - 분리합성곱 층은 일반 합성곱 층보다 파라미터, 메모리, 연산을 적게 쓰고 성능은 높다.

- SENet
  - 2017년 ILSVRC 우승 모델
  - GoogLeNet과 ResNet의 합성
  - 인셉션 모듈 + 잔차유닛에 SE block을 추가
  - ![img](http://formal.hknu.ac.kr/handson-ml2/slides/images/ch14/homl14-25.png)
  - SE Block 기능
    - 입력된 특성맵을 대상으로 깊이별 패턴 특성 분석을 한다.
    - 패턴 특성들을 파악한 후 출력값 보정
      - 관련없는 특성맵의 값을 줄인다.
  - SE Block 구조
    -  Global Avg. 풀링 → 밀집 은닉층 →밀집 출력층
    - 풀링층에서 평균 활성화 값 계산
    - 첫째 밀집 층은 뉴런의 수를 1/16로 줄인다.
    - 둘때 밀집 층은 뉴런 수를 정상화 시킨다.
      

- 케라스로 직접 구현하기 (실습코드)
  
- 분류와 위치추정
  - 위치를 표시하는 객체 주위의 경계상자
  - 경계상자의 4 좌표를 예측하면 된다 → 회귀모델로 구현 가능
  - 좌표 지도학습을 위한 Labeling에는 많은 시간비용이 필요함
  - 다양한 툴과 크라우드 소싱을 이용할 수 있다.
  - 경계상자의 평가지표 IoU(Intersection over union)
    - MSE를 쓸 수도 있지만, 이게 더 정확함.
    - 합집합에 대한 교집합의 비율
      
- 객체 탐지
  - 하나의 이미지에서 여러 개의 물체를 분류하고 위치를 추정하는 작업
  - CNN모델이 사진의 전체영역을 훑어보도록 하기.
    - 불필요한 경계상자 제거 필요
    - CNN 모델이 여러번 작동되어 매우 느림
  - 완전 합성곱 신경망(FCN)
    - CNN을 여러번 작동시키는 단점 해소
    - CNN에서의 최상위의 밀집층을 합성곱 층으로 교체함
    - 이미지를 한번만 처리하고도 CNN이 슬라이딩하면서 여러번 처리한 것과 동일한 효과
    - 동일 모델로 다양한 크기의 입력사진을 다룰 수 있다.
    - 목적에 따라 다른 합성곱 층으로 구성하여 여러객체를 탐지할 수 있다.
      
- YOLO
  - DNN 훈련 이전에 K-means 비지도 학습으로 간단한 앵커박스를 표시함.
  - 해당 데이터를 통해 객체 탐지에서 빠르고 정확하게 경계상자를 예측할 수 있다.
  - 훈련이 완료되면 비디오에 적용할 수 있을 정도로 빠르다.
    
- 시맨틱 분할
  - 경계상자가 아니고 픽셀로 분류하는 것.
  - 동일 부류의 객체는 서로 구분되지않음. (자동차 덩어리, 자전거들)
    <img src="https://ichi.pro/assets/images/max/724/1*xyofPxoHWTq7-icvNl4eCg.png" alt="시맨틱 분할 : 가장 강력한 컴퓨터 비전 작업" style="zoom:50%;" />
  - 기본 IDEA
    - CNN은 스트라이드가 1보다 큰 Convolution 혹은 풀링 층에 의해 점점 데이터가 뭉개진다.
    - 따라서 해상도를 다시 되돌리는 업샘플링 층을 추가해준다.
    - 일반적인 업샘플링은 이중 선형보간이지만  전치 합성곱층을 사용함
      <img src="https://ichi.pro/assets/images/max/724/1*8LqVEwW201vYN2JD1w_K4w.png" alt="img"  />
    - 정확도가 여전히 떨어짐
    - 스킵연결을 활용하여 아래층에서 부터 업샘플링을 진행
      - 풀링층에서 잃은 일부 공간 정보를 복원 할 수 있다.
      - 2배 업샘플링 → 아래층의 출력 더함 → 2배 업샘플링 → 더 아래층의 출력 더함 → 8배 업샘플링
      - 초해상도 : 이미지 해상도 증가에 사용할수 있음
  - 인스턴스 분할
    - 시맨틱 분할과 비슷하지만, 덩어리가 아니라 개별 객체를 모두 인식할 수 있음

